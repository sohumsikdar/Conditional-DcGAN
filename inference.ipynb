{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_9jkTFGL9xd"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import wandb\n",
        "import os\n",
        "import pickle\n",
        "from torch import nn\n",
        "from tqdm.notebook import tqdm\n",
        "import json\n",
        "from PIL import Image\n",
        "from torchvision import transforms, utils\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Ensure deterministic behavior taken from wandb docs\n",
        "torch.backends.cudnn.deterministic = True\n",
        "random.seed(3407)\n",
        "np.random.seed(3407)\n",
        "torch.manual_seed(3407)\n",
        "torch.cuda.manual_seed_all(3407)"
      ],
      "metadata": {
        "id": "e13CnEp0MIPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelEmbeds(nn.Module):\n",
        "    def __init__(self, embed_len):\n",
        "        super(LabelEmbeds,self).__init__()\n",
        "        self.embed_out = embed_len\n",
        "        self.embed_layer = nn.Sequential(\n",
        "            nn.Linear(in_features=1, out_features = embed_len),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, labels):\n",
        "        return self.embed_layer(labels)"
      ],
      "metadata": {
        "id": "m--KrdfCMNAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratorNetwork(nn.Module):\n",
        "    # stride=4 implies that every layer will increase the Height and Width by a factor of 2\n",
        "    \n",
        "    def __init__(self, embed_network, len_input, layer_channels):\n",
        "        super(GeneratorNetwork,self).__init__()\n",
        "\n",
        "        self.len_input = len_input\n",
        "\n",
        "        self.embed_network = embed_network\n",
        "\n",
        "        self.class_embed_layer = nn.Sequential(\n",
        "            nn.Linear(in_features=self.embed_network.embed_out, out_features = len_input//5),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.gen_layer_1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=len_input, out_channels=layer_channels*8, kernel_size=4, stride=1, padding=0),\n",
        "            nn.BatchNorm2d(layer_channels*8),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.gen_layer_2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=layer_channels*8, out_channels=layer_channels*4, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(layer_channels*4),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.gen_layer_3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=layer_channels*4, out_channels=layer_channels*2, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(layer_channels*2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.gen_layer_4 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=layer_channels*2, out_channels=layer_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(layer_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.gen_layer_5 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels=layer_channels, out_channels=3, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "        self.gan_all_layers = nn.Sequential(\n",
        "            self.gen_layer_1,\n",
        "            self.gen_layer_2,\n",
        "            self.gen_layer_3,\n",
        "            self.gen_layer_4,\n",
        "            self.gen_layer_5\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, class_labels, input_vec=None):\n",
        "        if input_vec == None:\n",
        "            # sample from gaussian dist\n",
        "            input_vec = torch.randn(class_labels.shape[0],4 * (self.len_input//5), 1, 1).to(device)\n",
        "    \n",
        "        embeds = self.embed_network(class_labels)\n",
        "        condition_input = self.class_embed_layer(embeds).reshape(class_labels.shape[0], -1, 1, 1)\n",
        "\n",
        "        gan_input = torch.cat([input_vec, condition_input], dim=1)\n",
        "\n",
        "        gan_out = self.gan_all_layers(gan_input)\n",
        "        return gan_out\n"
      ],
      "metadata": {
        "id": "FiR8Z4vnMNwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# b c h w\n",
        "# add new channel \n",
        "class DiscriminatorNetwork(nn.Module):\n",
        "    def __init__(self, embed_network, len_input, layer_channels):\n",
        "        super(DiscriminatorNetwork, self).__init__()\n",
        "        self.len_input = len_input\n",
        "\n",
        "        self.embed_network = embed_network\n",
        "\n",
        "        self.class_embed_layer = nn.Sequential(\n",
        "            nn.Linear(in_features=self.embed_network.embed_out, out_features = self.len_input),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # input: 4 x h x w, out: lc x h/2 x w/2\n",
        "        self.des_layer_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=4, out_channels=layer_channels, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        # input: lc x h/2 x w/2, out: lc * 2 x h/4 x w/4\n",
        "        self.des_layer_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=layer_channels, out_channels=layer_channels * 2, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(num_features=layer_channels * 2),\n",
        "            nn.LeakyReLU(negative_slope=0.2)\n",
        "        )\n",
        "\n",
        "        # input: lc * 2 x h/4 x w/4, out: lc * 4 x h/8 x w/8\n",
        "        self.des_layer_3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=layer_channels * 2, out_channels=layer_channels * 4, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(num_features=layer_channels * 4),\n",
        "            nn.LeakyReLU(negative_slope=0.2)\n",
        "        )\n",
        "\n",
        "        # input: lc * 4 x h/8 x w/8, out: lc * 8 x h/16 x w/16\n",
        "        self.des_layer_4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=layer_channels * 4, out_channels=layer_channels * 8, kernel_size=4, stride=2, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(num_features=layer_channels * 8),\n",
        "            nn.LeakyReLU(negative_slope=0.2)\n",
        "        )\n",
        "\n",
        "        self.classification_head = nn.Sequential(\n",
        "            nn.LazyLinear(out_features=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.des_conv_layers = nn.Sequential(\n",
        "            self.des_layer_1,\n",
        "            self.des_layer_2,\n",
        "            self.des_layer_3,\n",
        "            self.des_layer_4,\n",
        "        )\n",
        "    \n",
        "    def forward(self, images, class_labels):\n",
        "        # b, L\n",
        "        embeds = self.embed_network(class_labels)\n",
        "        # b, L, 1\n",
        "        embeds = self.class_embed_layer(embeds).reshape(class_labels.shape[0], self.len_input, 1)\n",
        "        # b, 1, L, L \n",
        "        embeds = embeds.repeat(1,1,self.len_input).reshape(class_labels.shape[0], 1, self.len_input, self.len_input)\n",
        "        input = torch.cat([images, embeds], dim=1)\n",
        "        out_conv = self.des_conv_layers(input).reshape(class_labels.shape[0],-1)\n",
        "        return self.classification_head(out_conv)"
      ],
      "metadata": {
        "id": "zP0bXONPMOfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Config = {\n",
        "    'batch_size':128,\n",
        "    'device': device,\n",
        "    'input_len': 100,\n",
        "    'dis_input_len':64,\n",
        "    'learning_rate': 2e-4,\n",
        "    'epochs': 120,\n",
        "    'image_size': (64, 64),\n",
        "    'last_epoch': 70\n",
        "}\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(Config[\"image_size\"]),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n"
      ],
      "metadata": {
        "id": "zVVRv7UVMQTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make(config):\n",
        "    embed_network = LabelEmbeds(config[\"input_len\"]//2).to(config[\"device\"])\n",
        "    gen_model = GeneratorNetwork(embed_network, len_input=100, layer_channels=96).to(config[\"device\"])\n",
        "    dis_model = DiscriminatorNetwork(embed_network, len_input=config[\"dis_input_len\"], layer_channels=64).to(config[\"device\"])\n",
        "\n",
        "    return gen_model, dis_model"
      ],
      "metadata": {
        "id": "xzVz1GYOMRgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model, dis_model = make(Config)"
      ],
      "metadata": {
        "id": "-QbLTvQBMSxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model.load_state_dict(torch.load('/content/drive/MyDrive/DL-trained-models/DL-CSE641/300-Epochs/trained-models/299_gen.pth'))\n",
        "dis_model.load_state_dict(torch.load('/content/drive/MyDrive/DL-trained-models/DL-CSE641/300-Epochs/trained-models/299_dis.pth'))"
      ],
      "metadata": {
        "id": "vq8GlnvCMXZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_image(gen_model, config, class_nums=None):\n",
        "    if class_nums == None:\n",
        "        class_nums = torch.Tensor([i+1 for i in range(102)]).reshape(102,1).to(device)\n",
        "        noise = torch.randn(102, 4* (config[\"input_len\"]//5), 1, 1).to(device)\n",
        "        \n",
        "    gen_images = gen_model(class_nums.float())\n",
        "    gen_images = (gen_images + 1) * 127.5\n",
        "\n",
        "    fig, axs = plt.subplots(17, 6, figsize=(20, 40))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    for i in range(102):\n",
        "        axs[i].imshow(gen_images[i].permute(1,2,0).long().cpu().numpy(), vmin=0, vmax=255)\n",
        "        axs[i].set_title(i)\n",
        "        \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "LGEXeKapMYWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}